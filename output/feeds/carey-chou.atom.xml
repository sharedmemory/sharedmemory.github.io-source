<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Shared Memory</title><link href="/" rel="alternate"></link><link href="/feeds/carey-chou.atom.xml" rel="self"></link><id>/</id><updated>2016-10-19T11:35:56+00:00</updated><entry><title>Adversarial Networks in Fashion</title><link href="/blog/2016/10/19/adversarial-networks-in-fashion/" rel="alternate"></link><published>2016-10-19T11:35:56+00:00</published><updated>2016-10-19T11:35:56+00:00</updated><author><name>Carey Chou</name></author><id>tag:,2016-10-19:blog/2016/10/19/adversarial-networks-in-fashion/</id><summary type="html">&lt;p&gt;Recent generative model research has developed a class of methods known as Generative Adversarial Networks (GANs).  These models adopt a game theoretic approach to training; two networks D (discriminator) and G (generator) "play a game" where D is trained to learn generated data from real data and G is trained to confuse D that the data it's generating is real.  Several variants of these networks [&lt;a href="https://arxiv.org/pdf/1511.05644v2.pdf"&gt;1&lt;/a&gt;, &lt;a href="http://arxiv.org/abs/1511.06434"&gt;2&lt;/a&gt;] have produced unbelieveably accurate samples.&lt;/p&gt;
&lt;h2&gt;Handbag Addition&lt;/h2&gt;
&lt;p&gt;This is a "fashion" edition of the results from [&lt;a href="http://arxiv.org/abs/1511.06434"&gt;2&lt;/a&gt;] where the authors perform vector arithmetic in z-space.  The classic example is:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;with man-with-glasses - man-without-glasses + woman = woman-with-glasses&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We applied similar methods specific to our industry using handbags.  We perform "arithmetic" on handbag features - that is, we reconstruct new handbags from the latent features of our network. The idea behind this is to take two popular handbags, let the GAN extract/merge their features, and then subtract them from features of a less popular handbag.  The transition is much more subtle and not obvious, and up to interpretation as to what features the final product extracts from each image.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="/images/handbag_addition_updated.jpg" title="Addition" /&gt;&lt;/p&gt;
&lt;p&gt;Taking 500 random points in z-space and varying the mean and standard deviation, we are able to generate what appears to be a transition from a handle-less clutch to much wider handbag with a handle.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="/images/handbag_transformation.jpg" title="Z-Transformation" /&gt;&lt;/p&gt;
&lt;h2&gt;Thoughts&lt;/h2&gt;
&lt;p&gt;An interesting experiemnt could be taking products that a shopper has viewed or purchased and using these techniques, create new patters/shapes/styles tailored specificlly to that individual.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Brendan Frey, Ian Goodfellow, Navdeep Jaitly, Alireza Maklhzani, and Jonathon Shlens.  Adversarial Autoencoders. &lt;em&gt;arXiv:1511.05644v2 [cs.LG]&lt;/em&gt;, 25 May 2016.&lt;/p&gt;
&lt;p&gt;[2] Soumith Chintala, Luke Metz, and Alec Radford.  Unsupervised Representation Learning
with Deep Convolutional Generative Adversarial Networks.  &lt;em&gt;arXiv:1511.06434v2&lt;/em&gt;, 07 January 2016.&lt;/p&gt;
&lt;p&gt;[3] Xi Chen, Viki Cheung, Ian Goodfellow, Alec Radford, Tim Salimans, Wojciech Zaremba.  Improved Techniques for Training GANs.  &lt;em&gt;arXivL1606.03498v1 [cs.LG]&lt;/em&gt;, 10 June 2016.&lt;/p&gt;</summary></entry><entry><title>Customer Choice Model and Attraction Effect</title><link href="/blog/2016/10/13/customer-choice-model-and-attraction-effect/" rel="alternate"></link><published>2016-10-13T09:41:11+00:00</published><updated>2016-10-13T09:41:11+00:00</updated><author><name>Carey Chou</name></author><id>tag:,2016-10-13:blog/2016/10/13/customer-choice-model-and-attraction-effect/</id><summary type="html">&lt;h2&gt;Context&lt;/h2&gt;
&lt;p&gt;Modeling customers' choices is a key technique in analyzing how purchase decisions are made and also, being able to quantify the magnitude of feature trade-offs across product functions in a customer's decision process.&lt;/p&gt;
&lt;p&gt;The basic idea of a choice model is to analyze which product a customer would prefer to purchase when she is presented with a collection of choices. For example, in fashion we want to analyze the scale of preference toward buying a black Gucci wallet priced at $2000 vs other choices of designers/colors priced $1500 to $3000. Most of the time, we are interested in much larger choice combinations (e.g. materials, promotion, shape).&lt;/p&gt;
&lt;p&gt;Traditional approaches to choice models (e.g. MLM) assumes IIA (Independence of Irrelevant Alternatives), which cannot represent certain key phenomena.  Several non-parametric methods have been studied and proposed; as we explored many of them, &lt;a href="four"&gt;4&lt;/a&gt; proposed an interesting RBM variation that extends MLM to represent several scenarios where choices vary among customers. It is also straightforward to implement. Here is our quick and simple experiment.&lt;/p&gt;
&lt;h2&gt;Problem Formulation&lt;/h2&gt;
&lt;p&gt;Our goal is to estimate individual the trade-off effect of purchase given a choice set. Eventually, we want to apply the individual trade-off effect to all customers who we can observe such behavior. Beyond trade-off, we are also interested in attraction effect – a driving force of a product to alternative products when it is presented in the choices.&lt;/p&gt;
&lt;p&gt;Many types of source data coming to mind when approaching this problem. Among them, website behavior is by far the richest; also we can directly observe each visitor's choices and her final selection. For each visitor to the website, we construct her choice set from products she viewed; the final selection is the product she purchased. We consider this level of design as demand based choice model.&lt;/p&gt;
&lt;p&gt;In our experiments, we explored other forms of problem designs, and each one of them reflects very different types of choice phenomena. For instance, we can treat a visitor’s purchases as our choice set, and then the select set represents only those products she eventually kept and not returned. This problem design reflects some subtle decision as related to actual fit, size, quality or price change.  We called this problem design utility based choice model.&lt;/p&gt;
&lt;p&gt;There are many such designs can be defined based on the business use cases. Here we share the experiment of demand based choices.&lt;/p&gt;
&lt;h2&gt;RBM Network&lt;/h2&gt;
&lt;p&gt;In our experiment the size of choice set is 18000 (total number of unique styles). The average choices (average number of unique styles per visitor) is around 13.  We implemented the solution using Python + Chainer on three NVIDIA GeForce TITAN X GPUs.  The network is a binary RBM (visible and hidden) with adaptive weight decay.  To speed up the training, we adopt K-contrastive divergence learning, which performs adaptive K-steps Gibbs sampling.  The weights are updated through reconstruction error on the visible layer via sigmoid cross entropy.a&lt;/p&gt;
&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;We used the trained hidden-to-visible weights to calculate choice rate, which is given by the formula:&lt;/p&gt;
&lt;div class="math"&gt;$$\lambda(A|\mathcal{X}) = \displaystyle\sum_{h}exp(-E_{\theta}((\upsilon^{\mathcal{X}}, \omega^{A}), h)) = exp(b_{A})\displaystyle\prod_{k}\sum_{h_{k} \in \{0,1\}}exp((T_{\mathcal{X}}^k + U_{A}^k)h_{k})$$&lt;/div&gt;
&lt;p&gt;We can use these probabilities to compare any two products in a choice set.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="/images/ysl_handbags.png" title="YSL" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="/images/ugly_handbag.png" title="Extreme Difference" /&gt;&lt;/p&gt;
&lt;p&gt;We can also use our validation data to contruct actual choice sets and compare those with network calculations.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Take the most frequent pairs of products in our validation data.&lt;/li&gt;
&lt;li&gt;Calculate their choice rate (this will be the "theoretical").&lt;/li&gt;
&lt;li&gt;Using validation data, calculate their choice rate from each choice set that they occur in (this will be the "actual").&lt;/li&gt;
&lt;li&gt;Calculate the KL-Divergence between these two distributions and use this metric as the graph weight.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="alt test" src="/images/graph.png" title="KLD-Graph" /&gt;&lt;/p&gt;
&lt;p&gt;We can also calculate an attraction effect.  If we have two products in a choice set, how does the addition of a third product affect customer choice? The strength of the attraction effect of a product C on A is defined as:&lt;/p&gt;
&lt;div class="math"&gt;$$\psi_{A,C,\mathcal{X}}^{(att)}\equiv\frac{p(A|\mathcal{X} \cup \{C\})}{p(A|\mathcal{X})}$$&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;When this equation is greater than one there is an attraction effect.&lt;/li&gt;
&lt;li&gt;Product B is preferred much more than product A.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="alt text" src="/images/pre_attraction.png" title="Before addition of attraction" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After the addition of a product C, the probability of product A has increased almost 15 fold.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="alt text" src="/images/post_attraction.png" title="Post attraction" /&gt;&lt;/p&gt;
&lt;div class="math"&gt;$$\frac{0.011424}{0.000762} = 14.987$$&lt;/div&gt;
&lt;p&gt;While not all product combinations exhibit this attractive behavior, several do and can be represented in a graph where the attractiveness is represented as an arrow (note our example in the bottom-right corner).&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt text" src="/images/attraction_graph.png" title="Attraction graph" /&gt;&lt;/p&gt;
&lt;h2&gt;Next Steps&lt;/h2&gt;
&lt;p&gt;&lt;a href="six"&gt;6&lt;/a&gt; introduces a deep choice model that combines autoencoder encoded features with RBM.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;&lt;a href="one"&gt;https://theses.lib.vt.edu/theses/available/etd-10152003-144051/unrestricted/thesis_etd.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="two"&gt;http://web.mit.edu/devavrat/www/Srikanth-Thesis.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="three"&gt;https://arxiv.org/pdf/0910.0063v4.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="four"&gt;http://pages.stern.nyu.edu/~gvulcano/EMPrefListsRev4.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="five"&gt;http://papers.nips.cc/paper/5280-restricted-boltzmann-machines-modeling-human-choice.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="six"&gt;http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12098&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' &amp;&amp; location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary></entry></feed>